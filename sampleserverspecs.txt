ETL Tuning RecommendationsThese are starting points for configuring the parallel Oracle ETL process based on server specifications. Monitoring and testing with realistic workloads are crucial to find the optimal settings for your specific environment and data.Key Parameters:parallelism: etl.engine.writer.parallelism (Number of concurrent writer threads per job)queueCapacity: etl.engine.writer.queueCapacity (Max rows buffered between reader & writers)batchSize: destination.batchSize (Rows per batch INSERT per writer)readerPoolSize: Max connections for the source DataSource poolwriterPoolSize: Max connections for the destination DataSource pool (must be >= parallelism * max concurrent jobs)Scenario 1: DEV ServerSpecs: 1 CPU, 250MB RAMConstraints: Very low CPU, extremely limited RAM. Database connections likely also limited. Prioritize stability and low resource usage over speed.JVM Heap (-Xmx): Set conservatively, e.g., -Xmx160m or -Xmx180m.Recommendation:parallelism: 1Reasoning: No benefit from multiple threads on a single CPU core; avoids context switching overhead.queueCapacity: 500Reasoning: Keep the buffer small to conserve heap memory. With only one writer, a large buffer isn't necessary.batchSize: 500Reasoning: Smaller batches reduce memory required by the single writer thread and minimize the impact of potential write failures/rollbacks.readerPoolSize: 1Reasoning: Only one reader thread active.writerPoolSize: 1 (or 2 absolute max if essential)Reasoning: Only one writer thread active. Keep pool minimal.Summary (DEV): Focus on minimal resource footprint. Run sequentially (parallelism: 1). Use small buffers and batches.Scenario 2: SIT ServerSpecs: 20 CPU, 2GB RAMConstraints: Good CPU, moderate RAM. Can support parallelism, but need to balance ETL server resources against database capacity and potential for multiple concurrent jobs.JVM Heap (-Xmx): Set based on available RAM, e.g., -Xmx1536m (1.5 GB).Option A: Balanced Approach (Good Starting Point)parallelism: 8Reasoning: Uses less than half the available cores, leaving significant CPU for the reader, OS, monitoring, potential DB activity on the same host (if applicable), and other concurrent jobs. Provides good parallelism without overwhelming a moderately capable database.queueCapacity: 10000Reasoning: A decent buffer to handle fluctuations between reader and the 8 writers without consuming excessive memory. (Estimate: 10k refs * ~100 bytes/ref = ~1MB, plus queue overhead).batchSize: 2500Reasoning: Moderate batch size balances network efficiency and memory per writer thread. (Estimate: 8 threads * 2500 rows * ~100 bytes/row = ~2MB for batch data refs, plus actual object data).readerPoolSize: 2Reasoning: Minimal pool for the single reader thread.writerPoolSize: 10 - 15Reasoning: Needs at least 8 for one job. This range allows for 1 job running at full parallelism plus some headroom or a second smaller job. Highly dependent on actual DB session limits.Option B: CPU-Focused (Requires Strong DB)parallelism: 16Reasoning: Leverages most CPU cores, assuming the database can handle this many concurrent writers and sessions efficiently without contention.queueCapacity: 15000Reasoning: Slightly larger queue as the reader might get ahead of 16 writers occasionally.batchSize: 1000Reasoning: Smaller batches when parallelism is very high to reduce the size and duration of individual database transactions and potential lock contention.readerPoolSize: 2writerPoolSize: 20 - 25Reasoning: Needs at least 16 for one job. Requires the database to comfortably handle this many concurrent sessions/transactions.Option C: Memory-Focused / Large Row Scenarioparallelism: 4Reasoning: Fewer concurrent writers if each row/batch consumes significant memory (e.g., large objects, complex processing state per thread) or if the DB is easily bottlenecked by connections/locks.queueCapacity: 5000Reasoning: Smaller queue might be sufficient if fewer writers are draining it.batchSize: 5000 - 10000Reasoning: Larger batches can improve efficiency (fewer round trips) when parallelism is lower, provided the memory per thread and DB transaction size are acceptable.readerPoolSize: 2writerPoolSize: 6 - 8Reasoning: Needs at least 4 for one job, plus some headroom.Important Considerations for ALL Scenarios:Database Limits: The single biggest factor is often the target database's capacity for concurrent sessions, transactions, CPU, memory (PGA), and I/O. Monitor the database closely (AWR, ASH, session waits) during tests. You might be forced to reduce parallelism or writerPoolSize due to DB limitations, regardless of ETL server specs.Concurrent Jobs: If multiple ETL jobs run simultaneously on the same engine instance, the total resource usage (CPU, RAM, DB connections) is cumulative. The writerPoolSize must accommodate the peak combined parallelism of all concurrent jobs. You might need lower per-job parallelism if many jobs run at once.Heap Monitoring: Closely monitor JVM heap usage (especially Old Generation) and Garbage Collection activity. If the heap grows uncontrollably or GC pauses are excessive, reduce queueCapacity, batchSize, or parallelism.Row Size: If your Row objects are large in memory, you'll need smaller queueCapacity and batchSize values than estimated here.Start Conservatively: Begin with lower parallelism (like Option A or C) and smaller batches/queues, measure performance and resource usage, and incrementally increase settings while monitoring stability.Test Data: Test with data volumes and characteristics that are representative of your production workload.Use these combinations as informed starting points, but rely on empirical testing and monitoring in each specific environment (DEV, SIT, PROD) to determine the truly optimal and stable configuration.
